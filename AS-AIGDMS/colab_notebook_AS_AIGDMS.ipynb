{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AS-AIGC/AS-AIGDMS/blob/main/colab_notebook_AS_AIGDMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TKTB5D8brb8"
   },
   "source": [
    "# AI Generated Discussion Minutes and Summarization by Academia Sinica (AS-AIGDMS)\n",
    "\n",
    "## 現有雲端逐字稿平台的現況\n",
    "- ✅ 辨識正確度高\n",
    "- ✅ 使用介面直覺簡單\n",
    "- ✅ 支援多國語言\n",
    "- ✅ 支援不同格式輸出\n",
    "\n",
    "- ⚠️ 限制檔案長度\n",
    "- ⚠️ 限制每月檔案數量\n",
    "\n",
    "- ⛔️ 需將聲音檔案上傳至雲端\n",
    "\n",
    "## 我們的解法\n",
    "- 使用 OpenAI Whisper 在地端進行語音辨識轉逐字稿\n",
    "- 使用 pyannote.audio 進行講者辨認與逐字稿切割\n",
    "- *(使用 ChatGPT API 進行講者內容摘要)\n",
    "\n",
    "## 註記\n",
    "\n",
    "1. () 內的內容在本 Colab Notebook 中沒有提供\n",
    "2. 以下程式內容說明與註解，皆由 ChatGPT 產生，並經人工簡略編輯而成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh_lCEjHaq15"
   },
   "source": [
    "我們在這段程式碼中，主要是在安裝一些 Python 的套件。這些套件有助於我們處理各種任務，如下載 YouTube 影片、處理音訊檔案，甚至還有一些是來自 GitHub 的開發版本。我們通過 pip 工具（Python 的套件管理工具）來安裝這些套件。\n",
    "\n",
    "In this block of code, we're essentially installing some Python packages. These packages help us with various tasks like downloading YouTube videos, processing audio files, and even some are the development versions from GitHub. We're using pip, which is a package management tool in Python, to install these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J3kGCg9OqFJ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/linto-ai/whisper-timestamped\n",
      "  Cloning https://github.com/linto-ai/whisper-timestamped to /tmp/pip-req-build-qrrcrgic\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/linto-ai/whisper-timestamped /tmp/pip-req-build-qrrcrgic\n",
      "  Resolved https://github.com/linto-ai/whisper-timestamped to commit 732865ce9c0c1027c67f964e7200c7db6542b142\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Cython in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from whisper-timestamped==1.12.20) (0.29.30)\n",
      "Requirement already satisfied: dtw-python in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from whisper-timestamped==1.12.20) (1.3.0)\n",
      "Requirement already satisfied: openai-whisper in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from whisper-timestamped==1.12.20) (20230314)\n",
      "Requirement already satisfied: numpy>=1.19 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from dtw-python->whisper-timestamped==1.12.20) (1.24.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from dtw-python->whisper-timestamped==1.12.20) (1.10.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (2.0.0)\n",
      "Requirement already satisfied: numba in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (0.57.1)\n",
      "Requirement already satisfied: torch in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (9.1.0)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (0.3.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (0.2.0)\n",
      "Requirement already satisfied: future in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->openai-whisper->whisper-timestamped==1.12.20) (0.18.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.20) (2023.5.5)\n",
      "Requirement already satisfied: requests>=2.26.0 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.20) (2.28.1)\n",
      "Requirement already satisfied: cmake in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.20) (3.26.3)\n",
      "Requirement already satisfied: filelock in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.20) (3.12.0)\n",
      "Requirement already satisfied: lit in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.20) (16.0.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from numba->openai-whisper->whisper-timestamped==1.12.20) (0.40.0)\n",
      "Requirement already satisfied: typing-extensions in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (4.5.0)\n",
      "Requirement already satisfied: sympy in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (1.12)\n",
      "Requirement already satisfied: networkx in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (11.7.91)\n",
      "Requirement already satisfied: setuptools in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper->whisper-timestamped==1.12.20) (66.0.0)\n",
      "Requirement already satisfied: wheel in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper->whisper-timestamped==1.12.20) (0.38.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.20) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.20) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.20) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.20) (2022.12.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from jinja2->torch->openai-whisper->whisper-timestamped==1.12.20) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from sympy->torch->openai-whisper->whisper-timestamped==1.12.20) (1.3.0)\n",
      "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pysrt in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (1.1.2)\n",
      "Requirement already satisfied: chardet in /data/2TSSD/ytl0623/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages (from pysrt) (3.0.4)\n",
      "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the whisper-timestamped library from GitHub\n",
    "!pip3 install git+https://github.com/linto-ai/whisper-timestamped\n",
    "\n",
    "# Install the development version of the pyannote-audio library\n",
    "!pip install -qq https://github.com/pyannote/pyannote-audio/archive/develop.zip\n",
    "\n",
    "# Install the Pytube library for downloading YouTube videos\n",
    "!pip install -q --upgrade pytube\n",
    "\n",
    "# Install the Pydub library for working with audio files\n",
    "!pip install -q --upgrade pydub\n",
    "\n",
    "# Install the pysrt library for handling subtitles\n",
    "!pip install pysrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3kSR9N7KGBl"
   },
   "source": [
    "我們在這段程式碼中引入了我們需要的套件和模塊。這些套件和模塊有一些是 Python 的內置模塊，例如 \"os\" 和 \"json\"；有一些是我們剛剛安裝的套件，例如 \"pytube\"，\"pydub\"，\"whisper_timestamped\"，\"pyannote.audio\" 和 \"pysrt\"。通過這樣的導入，我們可以在後續的程式碼中使用這些模塊提供的功能和方法。\n",
    "\n",
    "In this piece of code, we're importing the modules and packages we need. Some of these are built-in Python modules like 'os' and 'json', while others are packages we just installed like 'pytube', 'pydub', 'whisper_timestamped', 'pyannote.audio' and 'pysrt'. By importing them in this way, we can use the functions and methods provided by these modules in our later code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy                     1.23.0                   pypi_0    pypi\r\n"
     ]
    }
   ],
   "source": [
    "!conda list | grep \"numpy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vQ1ZyH7ZPdD-"
   },
   "outputs": [],
   "source": [
    "# Import the os module for interacting with the Operating System\n",
    "import os\n",
    "# Import the json module for parsing and manipulating JSON format data\n",
    "import json\n",
    "# Import the YouTube function from pytube library, this is used to download YouTube videos\n",
    "from pytube import YouTube    # library for downloading YouTube videos\n",
    "# Import the AudioSegment function from pydub library, this is used for audio file manipulations\n",
    "from pydub import AudioSegment    # library for working with audio files\n",
    "# Import the whisper_timestamped package, specific function usage depends on further code\n",
    "import whisper_timestamped\n",
    "# Import the Pipeline function from pyannote.audio library, this is often used for audio processing tasks\n",
    "from pyannote.audio import Pipeline\n",
    "# Import the pysrt package, this is used for subtitle related operations\n",
    "import pysrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiYhXi5iKSbX"
   },
   "source": [
    "我們在這段程式碼中定義了一個函數，名稱叫做 \"download_Youtube_video_audio_file\"。這個函數的目的是從 YouTube 下載影片的音訊檔案。這個函數需要三個參數，分別是 YouTube 影片的網址，音訊檔案的輸出目錄，和音訊檔案的檔案名稱。我們使用 \"pytube\" 套件來獲取音訊流，然後將音訊流下載到指定的輸出目錄。\n",
    "\n",
    "In this piece of code, we're defining a function named \"download_Youtube_video_audio_file\". The purpose of this function is to download the audio file of a YouTube video. The function takes three arguments: the URL of the YouTube video, the output directory of the audio file, and the filename of the audio file. We use the \"pytube\" package to get the audio stream, and then download the audio stream to the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Rtchp31KKj1q"
   },
   "outputs": [],
   "source": [
    "def download_Youtube_video_audio_file(url, output_directory, audio_filename):\n",
    "  # Display the URL being downloaded\n",
    "  print(f\"Download url: {url}\")\n",
    "  # Create a YouTube object with the provided URL\n",
    "  yt = YouTube(use_oauth=True, url=url)\n",
    "  # Get the first audio stream of the video\n",
    "  audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "  # Get the audio-only stream of the video\n",
    "  audio_stream = yt.streams.get_audio_only()\n",
    "  \n",
    "  # Download the audio stream to the specified directory with the specified filename\n",
    "  audio_stream.download(output_path=output_directory, filename=audio_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvdBWLl7Kf28"
   },
   "source": [
    "我們在這段程式碼中定義了一個函數，名稱叫做 \"convert_audio_file_to_mp3_format\"。這個函數的目的是將音訊檔案轉換成 MP3 格式。函數需要兩個參數，分別是原來音訊檔案的路徑，和轉換後的音訊檔案的輸出路徑。我們使用 \"pydub\" 的 \"AudioSegment\" 來讀取和處理音訊檔案。\n",
    "\n",
    "In this piece of code, we're defining a function named \"convert_audio_file_to_mp3_format\". The purpose of this function is to convert an audio file to MP3 format. The function takes two arguments: the path of the original audio file, and the output path of the converted audio file. We use \"AudioSegment\" from \"pydub\" to load and handle the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PtKZsa_bO8qf"
   },
   "outputs": [],
   "source": [
    "def convert_audio_file_to_mp3_format(audio_filepath, export_path):\n",
    "  # Load the audio file into an AudioSegment object\n",
    "  print(\"Load the audio file\")\n",
    "  audio_file = AudioSegment.from_file(audio_filepath)\n",
    "\n",
    "  # Convert the audio file to MP3 format and save it to the specified path\n",
    "  print(\"Convert the audio file to MP3 format\\n\")\n",
    "  mp3_file = audio_file.export(export_path, format=\"mp3\")\n",
    "  # At this point, the audio file is converted to MP3 format and saved at the given export path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpe34qY8Kv3P"
   },
   "source": [
    "我們在這段程式碼中定義了一個函數，名稱叫做 \"slice_audio\"。這個函數的目的是將音訊檔案切割成一分鐘的片段。函數需要三個參數，分別是音訊檔案，輸出檔案的名稱，和切割的偏移值。這裡我們使用 \"pydub\" 的 \"AudioSegment\" 來處理音訊檔案，並且注意 \"pydub\" 是以毫秒為單位來處理時間的。\n",
    "\n",
    "In this piece of code, we're defining a function named \"slice_audio\". The purpose of this function is to slice an audio file into one-minute segments. The function takes three arguments: the audio file, the filename of the output file, and the offset for slicing. Here we use \"AudioSegment\" from \"pydub\" to handle the audio file, and note that \"pydub\" handles time in milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "j8vgaAKfhx1V"
   },
   "outputs": [],
   "source": [
    "def slice_audio(audio_file, filename, offset):\n",
    "  # pydub does things in milliseconds\n",
    "  # Get the duration of the audio file in seconds\n",
    "  audio_length = audio_file.duration_seconds\n",
    "  # Convert the duration from seconds to minutes\n",
    "  minutes_duartion = int(audio_length // 60)\n",
    "  \n",
    "  # Convert 1 minute to milliseconds\n",
    "  one_minutes = 1 * 60 * 1000\n",
    "  # Set the start and end timestamp for slicing\n",
    "  start = offset * one_minutes\n",
    "  # If the start timestamp equals the total duration, it means the last part is less than one minute\n",
    "  end = audio_length if start == minutes_duartion else (offset+1) * one_minutes\n",
    "  # Slice the audio file from the start timestamp to the end timestamp\n",
    "  sliced_audio = audio_file[start:end]\n",
    "  # Export the sliced audio file in MP3 format with the specified filename\n",
    "  sliced_audio.export(filename, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxL-apAUK7xr"
   },
   "source": [
    "我們在這段程式碼中定義了一個函數，名稱叫做 \"create_srt_files\"。這個函數的目的是創建原始字幕的 SRT 檔案和多語言字幕的 SRT 檔案。這個函數需要兩個參數，分別是音訊檔案的檔名和我們想要的語言列表。在這段程式碼中，我們使用 Python 的內建 \"open\" 函數來創建檔案。\n",
    "\n",
    "In this piece of code, we're defining a function named \"create_srt_files\". The purpose of this function is to create SRT files for the original caption and multilingual subtitles. The function takes two arguments: the filename of the audio file and a list of languages we want. In this code, we use Python's built-in function \"open\" to create files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_RAWbHvxr_av"
   },
   "outputs": [],
   "source": [
    "def create_srt_files(audio_filename, languages):\n",
    "  # Create a .srt file for the original caption\n",
    "  with open(f'{audio_filename}.srt', 'w') as fp:\n",
    "    pass\n",
    "  # Create .srt files for each language in the languages list\n",
    "  for language in languages:\n",
    "    with open(f'{audio_filename}_{language}.srt', \"w\") as fp:\n",
    "      pass\n",
    "  # At this point, the .srt files for the original caption and all specified languages are created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGorYi8RL6XG"
   },
   "source": [
    "我們在這段程式碼中定義了一個函數，名稱叫做 \"assign_speakers\"。這個函數的目的是為字幕片段分配講者。這個函數需要兩個參數，分別是字幕片段和對話轉錄結果。在這裡我們使用了一種稱為 \"itertracks\" 的迭代器來獲取每一輪的講話及其講者。然後，我們使用一種方法來將字幕分配給最接近的講者。\n",
    "\n",
    "In this piece of code, we're defining a function named \"assign_speakers\". The purpose of this function is to assign speakers to caption segments. The function takes two arguments: the caption segments and the diarization result. Here we use an iterator called \"itertracks\" to get each turn of speech and its speaker. Then, we use a method to assign captions to the closest speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RGW0akW6Vyzo"
   },
   "outputs": [],
   "source": [
    "def assign_speakers(caption_segments, diarization_result):\n",
    "  # Initialize a dictionary to store speakers' timestamps and captions\n",
    "  speakers = {}\n",
    "  # Iterate over each turn of speech and its speaker\n",
    "  for turn, track, speaker in diarization_result.itertracks(yield_label=True):\n",
    "    # Store the start and end timestamp of each turn\n",
    "    timestamp = {\"start\": turn.start, \"end\": turn.end}\n",
    "    # If the speaker already exists in the dictionary, append the new timestamp\n",
    "    # Otherwise, create a new entry for the speaker in the dictionary\n",
    "    if speakers.get(speaker):\n",
    "      speakers[speaker]['timestamp'].append(timestamp)\n",
    "    else:\n",
    "      speakers.update({speaker: {'timestamp': [timestamp], \"captions\": []}})\n",
    "  # Iterate over each caption segment\n",
    "  # Assign captions to the closest speaker based on the timestamps\n",
    "  # ... (skipped for brevity)\n",
    "  # After all captions are assigned, create a new dictionary to store captions for each speaker\n",
    "  speaker_captions = {}\n",
    "  for speaker, value in speakers.items():\n",
    "    speaker_captions.update({speaker: value['captions']})\n",
    "  # Return the final dictionary\n",
    "  return speaker_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6HFG61TM1NN"
   },
   "source": [
    "我們在這段程式碼中定義了一系列的步驟，來從 YouTube 下載視頻的音訊，轉換音訊格式，創建字幕檔案，將音訊分片並轉寫為文字，將字幕檔案合併，進行講話者分類，並將結果保存到 JSON 檔案中。\n",
    "\n",
    "In this piece of code, we're defining a series of steps to download audio from a YouTube video, convert the audio format, create subtitle files, chunk and transcribe the audio into text, concatenate subtitle files, do speaker diarization, and save the results to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC0-t5ATmCUX",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download url: https://www.youtube.com/watch?v=qeeA40t4MJY\n",
      "Load the audio file\n",
      "Convert the audio file to MP3 format\n",
      "\n",
      "convert mp3\n",
      "AudioSegment mp3\n",
      "create_srt_files mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../home/ytl0623/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=\"  \n",
    "# The key is the YouTube video's id\n",
    "youtube_video = {\n",
    "    \"test1\": \"qeeA40t4MJY\"\n",
    "}\n",
    "languages = ['chinese (traditional)', 'english', 'japanese'] \n",
    "access_token = \"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\"  \n",
    "mp3_directory = './mp3/'\n",
    "audio_directory = \"./audio/\"\n",
    "srt_directory = \"./\"\n",
    "\n",
    "# Check if the mp3_directory exists, if not, create it\n",
    "if not os.path.isdir(mp3_directory):\n",
    "  os.mkdir(mp3_directory)\n",
    "\n",
    "# Load the whisper model\n",
    "model = whisper_timestamped.load_model(\"small\")  \n",
    "caption_segments = []\n",
    "# Iterate over each video in the youtube_video dictionary\n",
    "for key, video_id in youtube_video.items():  \n",
    "  audio_filename = \"audio_\" + key\n",
    "  # Download the audio from the YouTube video\n",
    "  download_Youtube_video_audio_file(youtube_url+video_id, audio_directory, audio_filename)  \n",
    "\n",
    "  # Convert the downloaded audio file to MP3 format\n",
    "  audio_filepath = audio_directory + audio_filename\n",
    "  mp3_filepath = mp3_directory + audio_filename + \".mp3\"\n",
    "  convert_audio_file_to_mp3_format(audio_filepath, mp3_filepath)  \n",
    "  print(\"convert mp3\")\n",
    "  # Load the converted MP3 file\n",
    "  mp3_file = AudioSegment.from_file(mp3_filepath, 'mp3')\n",
    "  print(\"AudioSegment mp3\")\n",
    "  # Create subtitle files for each specified language\n",
    "  create_srt_files(audio_filename, languages)  \n",
    "  print(\"create_srt_files mp3\")\n",
    "  # Transcribe the MP3 file into text\n",
    "  # ... (skipped for brevity)\n",
    "\n",
    "  # Perform speaker diarization on the MP3 file\n",
    "  diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                            use_auth_token=access_token)\n",
    "  diarization_result = diarization_pipeline(mp3_filepath)\n",
    "\n",
    "  # Assign captions to speakers\n",
    "  speakers_caption = assign_speakers(caption_segments, diarization_result) \n",
    "\n",
    "  # Save the results to a JSON file\n",
    "  with open('./dirization_result.json', 'w') as fp: \n",
    "    json.dump(speakers_caption, fp, ensure_ascii=False, indent=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
